{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, leaves_list, cut_tree\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# copy from xiong et al. attentivefp\n",
    "class ScaffoldGenerator(object):\n",
    "    \"\"\"\n",
    "    Generate molecular scaffolds.\n",
    "    Parameters\n",
    "    ----------\n",
    "    include_chirality : : bool, optional (default False)\n",
    "        Include chirality in scaffolds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, include_chirality=False):\n",
    "        self.include_chirality = include_chirality\n",
    "\n",
    "    def get_scaffold(self, mol):\n",
    "        \"\"\"\n",
    "        Get Murcko scaffolds for molecules.\n",
    "        Murcko scaffolds are described in DOI: 10.1021/jm9602928. They are\n",
    "        essentially that part of the molecule consisting of rings and the\n",
    "        linker atoms between them.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mols : array_like\n",
    "            Molecules.\n",
    "        \"\"\"\n",
    "        return MurckoScaffold.MurckoScaffoldSmiles(\n",
    "            mol=mol, includeChirality=self.include_chirality)\n",
    "\n",
    "\n",
    "# copy from xiong et al. attentivefp\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    \"\"\"Compute the Bemis-Murcko scaffold for a SMILES string.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    engine = ScaffoldGenerator(include_chirality=include_chirality)\n",
    "    scaffold = engine.get_scaffold(mol)\n",
    "    return scaffold\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4576287\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('./datasets/twoside/twosides_ge_500.csv'))\n",
    "scaffolds = {}\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n",
      "4576287\n"
     ]
    }
   ],
   "source": [
    "drug_set = set()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    drug_set.add(df.loc[i, 'Drug1'])\n",
    "    drug_set.add(df.loc[i, 'Drug2'])\n",
    "\n",
    "print(len(drug_set))\n",
    "\n",
    "for d in drug_set:\n",
    "    try:\n",
    "        scaffold = generate_scaffold(d)\n",
    "        if scaffolds.__contains__(scaffold):\n",
    "            scaffolds[scaffold] = scaffolds[scaffold] + 1\n",
    "        else:\n",
    "            scaffolds[scaffold] = 1\n",
    "    except:\n",
    "        print(\"error\", d)\n",
    "        # df.drop(index=i, inplace=True)\n",
    "        continue\n",
    "# print(len(df))\n",
    "# df = df.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "smile_scafold = {}\n",
    "for d in drug_set:\n",
    "    smile_scafold[d] = generate_scaffold(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    }
   ],
   "source": [
    "all_key = scaffolds.keys()\n",
    "print(len(all_key))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3639019 885260 52008 4576287\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# all_key = scaffolds.keys()\n",
    "# print(all_key)\n",
    "train_scaffold = random.sample(all_key, round(len(all_key) * 0.88))\n",
    "\n",
    "train_idx = []\n",
    "test1_idx = []\n",
    "test2_idx = []\n",
    "for i in range(len(df)):\n",
    "    if train_scaffold.__contains__(smile_scafold[df.loc[i, 'Drug1']]) \\\n",
    "            and train_scaffold.__contains__(smile_scafold[df.loc[i, 'Drug2']]):\n",
    "        train_idx.append(i)\n",
    "    elif not train_scaffold.__contains__(smile_scafold[df.loc[i, 'Drug1']]) \\\n",
    "            and not train_scaffold.__contains__(smile_scafold[df.loc[i, 'Drug2']]):\n",
    "        test2_idx.append(i)\n",
    "    else:\n",
    "        test1_idx.append(i)\n",
    "print(len(train_idx), len(test1_idx), len(test2_idx), len(train_idx)+len(test1_idx)+len(test2_idx))\n",
    "if len(train_idx) > 3600000:\n",
    "    df_old = df.loc[train_idx]\n",
    "    df_old = df_old.reset_index()\n",
    "    df_old.to_csv('./datasets/twoside/twoside_train_val.csv')\n",
    "\n",
    "    df_test1_idx = df.loc[test1_idx]\n",
    "    df_test1_idx = df_test1_idx.reset_index()\n",
    "    df_test1_idx.to_csv('./datasets/twoside/twoside_test1.csv')\n",
    "\n",
    "    df_test2_idx = df.loc[test2_idx]\n",
    "    df_test2_idx = df_test2_idx.reset_index()\n",
    "    df_test2_idx.to_csv('./datasets/twoside/twoside_test2.csv')\n",
    "    print(\"done\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def search_index(unique_smiles, df, num_class, num_limit):\n",
    "\n",
    "    vec_list = []\n",
    "    for smi in unique_smiles:\n",
    "        m1 = Chem.MolFromSmiles(smi)\n",
    "        fp4 = list(AllChem.GetMorganFingerprintAsBitVect(m1, radius=2, nBits=256))\n",
    "        vec_list.append(fp4)\n",
    "    print(\"drug num\", len(vec_list))\n",
    "    Z = linkage(vec_list, 'average', metric='jaccard')\n",
    "    cluster = cut_tree(Z, num_class).ravel()\n",
    "    stat_dict = {k: v for k, v in sorted(Counter(cluster).items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    num = 0\n",
    "    data_dict = defaultdict(list)\n",
    "    for k,v in stat_dict.items():\n",
    "        pos = np.nonzero(cluster==k)[0]\n",
    "        # print(k, stat_dict[k], len(pos))\n",
    "        smi_idx = []\n",
    "        for idx in pos:\n",
    "            smi_single = df[df[\"Drug1\"] == unique_smiles[idx]]\n",
    "            smi_idx.append(smi_single)\n",
    "        df_tmp = pd.concat(smi_idx)\n",
    "        num += len(df_tmp)\n",
    "        data_dict[k] = df_tmp\n",
    "    print(\"@@@@@@@@@@@\", len(data_dict.keys()), num)\n",
    "\n",
    "    num = 0\n",
    "    all_keys = list(data_dict.keys())\n",
    "    class_num = -1\n",
    "    meat_class = {}\n",
    "    for k,v in data_dict.items():\n",
    "        if len(v) > num_limit:\n",
    "            class_num += 1\n",
    "            meat_class[class_num] = v\n",
    "            num += len(v)\n",
    "            all_keys.remove(k)\n",
    "\n",
    "    random.shuffle(all_keys)\n",
    "\n",
    "    smi_idx = []\n",
    "    smi_idx_num = 0\n",
    "    for i,k in enumerate(all_keys):\n",
    "        # print(i, len(data_dict[k]))\n",
    "        if smi_idx_num < num_limit:\n",
    "            smi_idx.append(data_dict[k])\n",
    "            smi_idx_num += len(data_dict[k])\n",
    "        else:\n",
    "            class_num += 1\n",
    "            meat_class[class_num] = pd.concat(smi_idx)\n",
    "            num += len(meat_class[class_num])\n",
    "\n",
    "            smi_idx = []\n",
    "            smi_idx_num = 0\n",
    "            smi_idx.append(data_dict[k])\n",
    "            smi_idx_num += len(data_dict[k])\n",
    "\n",
    "        if i == len(all_keys) -1:\n",
    "            class_num += 1\n",
    "            meat_class[class_num] = pd.concat(smi_idx)\n",
    "            num += len(meat_class[class_num])\n",
    "\n",
    "\n",
    "    print(class_num, len(meat_class[class_num]),num)\n",
    "\n",
    "    if len(meat_class[class_num]) < 10:\n",
    "        meat_class.pop(class_num)\n",
    "\n",
    "    num = 0\n",
    "    for k,v in meat_class.items():\n",
    "        num += len(v)\n",
    "    print(num)\n",
    "\n",
    "    return meat_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug num 578\n",
      "@@@@@@@@@@@ 100 3639019\n",
      "94 164 3639019\n",
      "3639019\n",
      "95\n",
      "2724872 76 914147 19 3639019\n"
     ]
    },
    {
     "data": {
      "text/plain": "['datasets/twoside/twoside_val.pkl']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('datasets/twoside/twoside_train_val.csv')\n",
    "unique_smi = set(df_train[\"Drug1\"].unique())\n",
    "unique_smi_aa = unique_smi.union(set(df_train[\"Drug2\"].unique()))\n",
    "meat_class = search_index(list(unique_smi_aa), df_train, 100, 150)\n",
    "# meat_class = search_index(unique_smi, df, 100, 100)\n",
    "print(len(meat_class.keys()))\n",
    "meta_train = {}\n",
    "meta_train_num = 0\n",
    "meta_train_k_num = 0\n",
    "meta_val = {}\n",
    "meta_val_num = 0\n",
    "meta_val_k_num = 0\n",
    "meta_keys = list(meat_class.keys())\n",
    "random.shuffle(meta_keys)\n",
    "for k in meta_keys:\n",
    "    if len(meta_train.keys()) < len(meta_keys) *0.8:\n",
    "        meta_train[k] = meat_class[k]\n",
    "        meta_train_num += len(meat_class[k])\n",
    "        meta_train_k_num += 1\n",
    "    else:\n",
    "        meta_val_k_num +=1\n",
    "        meta_val[k] = meat_class[k]\n",
    "        meta_val_num += len(meat_class[k])\n",
    "print(meta_train_num, meta_train_k_num,meta_val_num,meta_val_k_num, meta_train_num+meta_val_num)\n",
    "joblib.dump(meta_train, \"datasets/twoside/meta_train.pkl\")\n",
    "joblib.dump(meta_val, \"datasets/twoside/meta_val.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug num 535\n",
      "@@@@@@@@@@@ 50 885260\n",
      "47 170 885260\n",
      "885260\n"
     ]
    },
    {
     "data": {
      "text/plain": "['datasets/twoside/twoside_test1.pkl']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/twoside/twoside_test1.csv')\n",
    "# df = pd.read_csv('datasets/twoside/twoside_test2.csv')\n",
    "unique_smi = df[\"Drug1\"].unique()\n",
    "meat_class = search_index(unique_smi, df, 50, 200)\n",
    "joblib.dump(meat_class, \"datasets/twoside/meta_test1.pkl\")\n",
    "# joblib.dump(meat_class, \"datasets/twoside/meta_test2.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2724872\n",
      "914147\n"
     ]
    }
   ],
   "source": [
    "meta_train = joblib.load(\"datasets/twoside/twoside_train.pkl\")\n",
    "meta_val = joblib.load(\"datasets/twoside/twoside_val.pkl\")\n",
    "train_pd = []\n",
    "for k,v in meta_train.items():\n",
    "    train_pd.append(v)\n",
    "df_tmp = pd.concat(train_pd)\n",
    "df_tmp = df_tmp.reset_index(drop=True)\n",
    "df_tmp.to_csv('./datasets/twoside/twoside_train.csv')\n",
    "print(len(df_tmp))\n",
    "\n",
    "test_pd = []\n",
    "for k,v in meta_val.items():\n",
    "    test_pd.append(v)\n",
    "df_tmp = pd.concat(test_pd)\n",
    "df_tmp = df_tmp.reset_index(drop=True)\n",
    "df_tmp.to_csv('./datasets/twoside/twoside_val.csv')\n",
    "\n",
    "print(len(df_tmp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}